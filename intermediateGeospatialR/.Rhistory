<<<<<<< HEAD
# set some standard parameter for the documents.
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
=======
}
if(raster::extent(raster)< raster::extent(extent)){
print("The raster may be smaller then the extent object")
}
if(!raster::compareCRS(x = raster, y = extent)){
return("The crs of the objects to not overlap")
}else{
return(raster%>%
raster::crop(y = extent)%>%
raster::mask(mask = extent))
for(i in seq_along(images)){
r1 <- raster::raster(images[i]) # read in the raster
nameR <- names(r1) # save the name as a variable to use in the file structure later
}
for(j in seq_along(counties$STATEFP)){
c1 <- counties[j,] # select a specific county
nameC <- as.character(c1$NAME) # grab the name of the county
r2 <- clipMask2(raster = r1, extent = c1) # call the function with input from the loop above
### we've already written this content out so we don't need to repeat the process
# raster::writeRaster(x = r2,filename = paste0(baseDir, "/data/nightLights/", nameC,"/",nameR,".tif"))
}
# loop over images
for(i in seq_along(images)){
r1 <- raster::raster(images[i])
nameR <- names(r1)
# loop over counties
for(j in seq_along(counties$STATEFP)){
c1 <- counties[j,]
nameC <- as.character(c1$NAME)
r2 <- clipMask2(raster = r1, extent = c1)
### we've already writen this content out so we don't need to repeat the process.
# raster::writeRaster(x = r2,filename = paste0(baseDir, "/data/nightLights/", nameC,"/",nameR,".tif"))
}
}
head(censusT)
dim(censusT)
length(unique(censusT$GEOID))
# Grab unique variables.
vals <- unique(censusT$variable)
### B01002_001 == median age
### B17001_002 == poverty
#Base R
c1 <- censusT[censusT$variable == vals[1], ]
# dplyr
c1 <- dplyr::filter(censusT, variable == vals[1])
c2 <- censusT %>% ## use dplyr so we can pipe some more transformations
as.data.frame() %>% # convert to df to drop geometry column so that is not transferred
dplyr::filter(variable == vals[2])%>%
dplyr::select("GEOID", "variable", "estimate", "moe")# drop duplicated features besides GEOID
## we can join and retain a spatial objects
censusData <- dplyr::left_join(x = c1, y = c2, by = "GEOID")
names(censusData)
colnames(censusData) <- c("GEOID","NAME","medianAge","estimate_age","moe_age","poverty","estimate_poverty","moe_poverty","geometry")
# map the first 10 rows of the new dataset
qtm(censusData[1:10,])
## create a subset to test the process.
r1 <- raster::raster("data/nightLights/Harris/june_10arc.tif")
head(censusData) # check for harris county locations
# pull a subset
t2 <- censusData[2:4,]
# extract values to a vector
t2$june_values <-raster::extract(x = r1, y = t2) ## maintain all features
# View(t2)
## generate a summarize radiance over each element of the spatial feature
t2$june <- raster::extract(x = r1, y = t2, fun = mean)
## convert to new measure
t2$june_mean2 <-lapply(t2$june_values, FUN=mean)
qtm(t2)
View(censusData)
# pull the geoid for a county
id <- as.numeric(counties[1,"GEOID"])[1] ## this is returned as a list so there is an extra level of indexing to get the numeric value
# test for partial match across census tracks
matches <- grepl(pattern = id, x = censusData$GEOID)
# partial match example
val <- 48029
items <- c(48029, 3048548029, 123045480290320487)
# test for partial match against all items
grepl(pattern = val, x = items)
# tests for exact match against any one item
val %in% items
qtm(censusData[matches, ])
# loop over counties
for(i in seq_along(counties$STATEFP)){
# select GEOID, convert to numeric and index to drop geom
id <- as.numeric(as.data.frame(counties)[i,"GEOID"])
## subset the census data connected to a specific county
c1 <- censusData[grepl(pattern = id, x = censusData$GEOID),][1:3, ] ### we're only looking at the first few records because this will take a long time to run. 1,200 census tracks, 12 images = 14,400 spatial operations. Pretty sweet! Aren't you glad you're not clicking through this workflow :)
# construct a file directory to show where to look for specific county images
cName <- as.character(counties$NAME[i])
dir <- paste0(baseDir, "/data/nightLights/",cName)
## pull all rasters from a county of interest
rasters <- list.files(path = dir, pattern = ".tif", full.names = TRUE)
}
# loop over counties
for(i in seq_along(counties$STATEFP)){
# select GEOID, convert to numeric and index to drop geom
id <- as.numeric(as.data.frame(counties)[i,"GEOID"])
## subset the census data connected to a specific county
c1 <- censusData[grepl(pattern = id, x = censusData$GEOID),][1:3, ] ### we're only looking at the first few records because this will take a long time to run. 1,200 census tracks, 12 images = 14,400 spatial operations. Pretty sweet! Aren't you glad you're not clicking through this workflow :)
# construct a file directory to show where to look for specific county images
cName <- as.character(counties$NAME[i])
dir <- paste0("data/nightLights/",cName)
## pull all rasters from a county of interest
rasters <- list.files(path = dir, pattern = ".tif", full.names = TRUE)
}
for(j in rasters){
print(j)
r2 <- raster::raster(j) # read in image
n1 <- names(r2)
# assigning column based on raster name and calculate mean value per area
c1[,n1]  <- raster::extract(x =r2, y = c1, fun = mean)[,1] # extract returns a matrix, so we are indexing the column so we can store the data as a vector within the sf object.
### note were are adding to a dataframe as we run through this loop. That's
### not always the best thing to do. I just didn't want to write out column
### names before hand... efficiency is great but it's also not everything.
}
## condition to compile the datasets
if(i == 1) { # if we are in the first iteration of the loop, declare the new variable df
df <- c1
} else { # when we are in a new iteration, add the data to the existing df variable. This build the dataframe.
df <- dplyr::bind_rows(df, c1)
}
# loop over counties
for(i in seq_along(counties$STATEFP)){
# select GEOID, convert numeric and index to drop geom
id <- as.numeric(as.data.frame(counties)[i,"GEOID"])
## subset the census data connected to a specific county
c1 <- censusData[grepl(pattern = id, x = censusData$GEOID),][1:3, ]
# construct a file directory to show where to look for specific county images
cName <- as.character(counties$NAME[i])
dir <- paste0(baseDir, "/data/nightLights/",cName)
## pull all rasters from a county of interest
rasters <- list.files(path = dir,pattern = ".tif", full.names = TRUE)
for(j in rasters){
print(j)
r2 <- raster::raster(j) # read in image
n1 <- names(r2)
# assigning column based on raster name and calculate mean value per area
c1[,n1]  <- raster::extract(x =r2, y = c1, fun = mean)[,1] # extract returns a matrix so we are indexing the column so we can store the data as a vector within the sf object.
}
## condition to compile the datasets, outside of the "j" loop
if(i == 1){
df <- c1
}else{
df <- dplyr::bind_rows(df, c1)
}
}
# loop over counties
for(i in seq_along(counties$STATEFP)){
# select GEOID, convert numeric and index to drop geom
id <- as.numeric(as.data.frame(counties)[i,"GEOID"])
## subset the census data connected to a specific county
c1 <- censusData[grepl(pattern = id, x = censusData$GEOID),][1:3, ]
# construct a file directory to show where to look for specific county images
cName <- as.character(counties$NAME[i])
dir <- paste0("/data/nightLights/",cName)
## pull all rasters from a county of interest
rasters <- list.files(path = dir,pattern = ".tif", full.names = TRUE)
for(j in rasters){
print(j)
r2 <- raster::raster(j) # read in image
n1 <- names(r2)
# assigning column based on raster name and calculate mean value per area
c1[,n1]  <- raster::extract(x =r2, y = c1, fun = mean)[,1] # extract returns a matrix so we are indexing the column so we can store the data as a vector within the sf object.
}
## condition to compile the datasets, outside of the "j" loop
if(i == 1){
df <- c1
}else{
df <- dplyr::bind_rows(df, c1)
}
}
# check the output
# View(df)
# you can write this out if you want, but I'm not going to yet
sf::write_sf("outputs/censusNightLightRadiance.shp")
# let's also drop the spatial feature so it plays a little nicer with some functions.
df2 <- as.data.frame(df)
names(df)
# calculate the yearly average radiance for each
df2$averageRadiance <- rowMeans(df2[,9:20])
print(df2)
View(df2)
?rowMeans
# loop over counties
for(i in seq_along(counties$STATEFP)){
# select GEOID, convert numeric and index to drop geom
id <- as.numeric(as.data.frame(counties)[i,"GEOID"])
## subset the census data connected to a specific county
c1 <- censusData[grepl(pattern = id, x = censusData$GEOID),][1:3, ]
# construct a file directory to show where to look for specific county images
cName <- as.character(counties$NAME[i])
dir <- paste0("/data/nightLights/",cName)
## pull all rasters from a county of interest
rasters <- list.files(path = dir,pattern = ".tif", full.names = TRUE)
for(j in rasters){
print(j)
r2 <- raster::raster(j) # read in image
n1 <- names(r2)
# assigning column based on raster name and calculate mean value per area
c1[,n1]  <- raster::extract(x =r2, y = c1, fun = mean)[,1] # extract returns a matrix so we are indexing the column so we can store the data as a vector within the sf object.
}
## condition to compile the datasets, outside of the "j" loop
if(i == 1){
df <- c1
}else{
df <- dplyr::bind_rows(df, c1)
}
}
# check the output
# View(df)
# set some standard parameter for the documents.
knitr::opts_chunk$set(echo = FALSE, echo=FALSE, message=FALSE, warning=FALSE)
# load required libraries
library(sf)
library(raster)
library(dplyr)
library(tmap)
## change this to where every your folder is.
baseDir <- "~/Desktop/R_SC_Spatial-master/intermediateGeospatialR"
## night light imagery
images <- list.files(path = paste0(baseDir, "/data/nightLights"),
pattern = ".tif",
full.names = TRUE)
# summary(images)
## county locations
counties <- sf::st_read(dsn = paste0(baseDir,"/data/counties/countyTex.shp"))
# loop over counties
for(i in seq_along(counties$STATEFP)){
# select GEOID, convert numeric and index to drop geom
id <- as.numeric(as.data.frame(counties)[i,"GEOID"])
## subset the census data connected to a specific county
c1 <- censusData[grepl(pattern = id, x = censusData$GEOID),][1:3, ]
# construct a file directory to show where to look for specific county images
cName <- as.character(counties$NAME[i])
dir <- paste0("data/nightLights/",cName)
## pull all rasters from a county of interest
rasters <- list.files(path = dir,pattern = ".tif", full.names = TRUE)
for(j in rasters){
print(j)
r2 <- raster::raster(j) # read in image
n1 <- names(r2)
# assigning column based on raster name and calculate mean value per area
c1[,n1]  <- raster::extract(x =r2, y = c1, fun = mean)[,1] # extract returns a matrix so we are indexing the column so we can store the data as a vector within the sf object.
}
## condition to compile the datasets, outside of the "j" loop
if(i == 1){
df <- c1
}else{
df <- dplyr::bind_rows(df, c1)
}
}
# check the output
# View(df)
# let's also drop the spatial feature so it plays a little nicer with some functions.
df2 <- as.data.frame(df)
names(df)
# calculate the yearly average radiance for each
df2$averageRadiance <- rowMeans(df2[,9:20])
#HP!: What is supposed to be calculated here? Columns 9 - 20 don't exist in df2.
# View(df2)
### We now have an average yearly radiance for each location, so let's plot the relationship against radiance and see what we see.
library(ggplot2)
ggplot(df2, aes(x = averageRadiance, y = estimate_age)) +
geom_point() +
facet_wrap( ~ NAME)
age <- ggplot(df2, aes(estimate_age, averageRadiance)) +
geom_point() +
stat_smooth()
poverty <- ggplot(df2, aes(estimate_poverty, averageRadiance)) +
geom_point() +
stat_smooth()
age
poverty
# use apply to perform a row-wise operation on the data
df2$varianceRadiance <- apply(X = df2[,9:20],MARGIN = 1,FUN = sd)
df2[,c(2,22,23)]
# assign values from our dataframe df2 to the spatial object.
df$averageRadiance <- df2$averageRadiance
# create a facet map to show the census tracts.
tm_shape(df) +
tm_polygons(c("averageRadiance", "estimate_poverty", "estimate_age")) +
tm_facets(sync = TRUE, ncol = 3)
# set some standard parameter for the documents.
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
knitr::include_graphics("./data/pngsForMarkdown/light.jpg")
#[By InSapphoWeTrust from Los Angeles, California, USA - Light beam, Luxor, Las Vegas, CC BY-SA 2.0, https://commons.wikimedia.org/w/index.php?curid=24267782.]
# set some standard parameter for the documents.
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
knitr::include_graphics("data/pngsForMarkdown/peopleLight.jpg")
knitr::include_graphics("data/pngsForMarkdown/peopleLight.jpg")
#Photo by <a href="https://unsplash.com/@vingtcent?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Vincent Guth</a> on <a href="https://unsplash.com/s/photos/headlamps?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
knitr::include_graphics("data/pngsForMarkdown/buildingLight.jpg")
# Photo by <a href="https://unsplash.com/@redaska?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">steve pancrate</a> on <a href="https://unsplash.com/s/photos/building-lights?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
knitr::include_graphics("data/pngsForMarkdown/moonSnow.jpg")
# Photo by <a href="https://unsplash.com/@jevanleith?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Evan Leith</a> on <a href="https://unsplash.com/s/photos/moonlight?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
knitr::include_graphics("data/pngsForMarkdown/texasClouds.png")
# https://www.weather-us.com/en/texas-usa/houston-climate#cloud
>>>>>>> c570d24 (Rproj organization and relative path changes)
# load required libraries
library(sf)
library(raster)
library(dplyr)
library(tmap)
<<<<<<< HEAD
## change this to the directory where your folder is stored
baseDir <- "D:/R_SC_Spatial/intermediateGeospatialR"
=======
rm(list = ls())
>>>>>>> c570d24 (Rproj organization and relative path changes)
# grab all counts images
images <- list.files(path = paste0(baseDir,"/data/nightLights"),
pattern = "_counts.tif",
full.names = TRUE)
<<<<<<< HEAD
images
## change this to the directory where your folder is stored
baseDir <- "~/Desktop/R_SC_Spatial/intermediateGeospatialR"
# grab all counts images
images <- list.files(path = paste0(baseDir,"/data/nightLights"),
pattern = "_counts.tif",
full.names = TRUE)
# grab all counts images
images <- list.files(path = paste0(baseDir,"/data/nightLights"),
=======
# grab all counts images
images <- list.files(path = "data/nightLights"),
# grab all counts images
images <- list.files(path = "data/nightLights",
>>>>>>> c570d24 (Rproj organization and relative path changes)
pattern = "_counts.tif",
full.names = TRUE)
images
# read in image
temp1 <- raster::raster(images[1])
temp1
# grab a radiance image
<<<<<<< HEAD
allImages <- list.files(path = paste0(baseDir,"/data/nightLights"),
=======
allImages <- list.files(path = "data/nightLights",
>>>>>>> c570d24 (Rproj organization and relative path changes)
pattern = ".tif",
full.names = TRUE,
recursive = TRUE)
# print to find an image from a county
allImages[1:10]
# read in county processed image
r1 <- raster::raster(allImages[5])
# crop the raster
temp2 <- temp1 %>%
raster::crop(r1)
# pull attributes and view
<<<<<<< HEAD
temp2
qtm(temp2)
=======
qtm(temp2)
temp2
>>>>>>> c570d24 (Rproj organization and relative path changes)
# grab the values of the raster object
vals <- raster::values(temp2)
# summary() base R
summary(vals)
# plot a histogram
hist(vals)
# create a mask object
mask <- r1
# reassing all positive values to 1
mask[mask >= 0, ] <- 1
# set any value not equal to 1 as NA
mask[mask != 1, ] <- NA
# multiple raster to apply the mask
counts <- temp2 * mask
qtm(counts)
vals2 <- raster::values(counts)
summary(vals2)
hist(vals2)
# pull total number of observations
vals_noNA <- vals2[!is.na(vals2)]
total <- length(vals_noNA)
# determine sequence of interest
seq1 <- seq(min(vals_noNA),max(vals_noNA), by =1 )
getArea <- function(values,  index){
### values: vector of numerical features
### index: numerical value to filter on
# add na clause just to be safe
values <- values[!is.na(values)]
# get total
total <- length(values)
# get new values based on index
vals_new <- values[values >= index]
# calc average
ave <- 100*(length(vals_new)/ total)
return(ave)
}
<<<<<<< HEAD
=======
# create a dataframe to store content
df <- data.frame(matrix(nrow = length(seq1), ncol = 2))
names(df) <- c("filter", "percent area")
# assign the filter element because we have it already
df$filter <- seq1
for(i in seq_along(seq1)){
# index column position using i, but define the filter value by seq1 feature
df$`percent area`[i] <- getArea(values = vals_noNA, index = seq1[i])
}
df
n = 1
for(i in seq1){
# index column position using i, but define the filter value by seq1 feature
df$`percent area`[n] <- getArea(values = vals_noNA, index = i)
n = n + 1
}
df
# create a dataframe to store content
df <- data.frame(matrix(nrow = length(seq1), ncol = 4))
### adding new columns for mean and median
names(df) <- c("filter", "percent area", "mean", "median")
# assign the filter element because we have it already
df$filter <- seq1
# Check to make sure the original feature we read in matches our month of interest
r1
temp1
## speculating on workflow, do not run
i <- "filter level"
## create a mask of the counts layer
counts[counts >= i, ] <- 1
temp2
# pull total number of observations
vals_noNA <- vals2[!is.na(vals2)]
total <- length(vals_noNA)
# determine sequence of interest
seq1 <- seq(min(vals_noNA),max(vals_noNA), by =1 )
>>>>>>> c570d24 (Rproj organization and relative path changes)
getArea <- function(values,  index){
### values: vector of numerical features
### index: numerical value to filter on
# add na clause just to be safe
values <- values[!is.na(values)]
# get total
total <- length(values)
# get new values based on index
vals_new <- values[values >= index]
# calc average
ave <- 100*(length(vals_new)/ total)
return(ave)
}
# create a dataframe to store content
df <- data.frame(matrix(nrow = length(seq1), ncol = 2))
names(df) <- c("filter", "percent area")
# assign the filter element because we have it already
df$filter <- seq1
for(i in seq_along(seq1)){
# index column position using i, but define the filter value by seq1 feature
df$`percent area`[i] <- getArea(values = vals_noNA, index = seq1[i])
}
df
n = 1
for(i in seq1){
# index column position using i, but define the filter value by seq1 feature
df$`percent area`[n] <- getArea(values = vals_noNA, index = i)
n = n + 1
}
df
# create a dataframe to store content
df <- data.frame(matrix(nrow = length(seq1), ncol = 4))
### adding new columns for mean and median
names(df) <- c("filter", "percent area", "mean", "median")
# assign the filter element because we have it already
df$filter <- seq1
# Check to make sure the original feature we read in matches our month of interest
r1
temp1
<<<<<<< HEAD
## speculating on workflow
=======
## speculating on workflow, do not run
>>>>>>> c570d24 (Rproj organization and relative path changes)
i <- "filter level"
## create a mask of the counts layer
counts[counts >= i, ] <- 1
radMeanAndMedian <- function(countRaster, radianceRaster, index){
## create a mask of the counts layer
countRaster[countRaster < index] <- NA
countRaster[countRaster >= index] <- 1
##  apply the mask to the radiance layer
rad1 <- radianceRaster * countRaster
## remove all NA values
rad_vals <- raster::values(rad1)
rad_vals <- rad_vals[!is.na(rad_vals)]
## create a vector to store outputs
values <- c()
## calculate mean and median
values[1] <- mean(rad_vals)
values[2] <- median(rad_vals)
return(values)
}
# define input parameters
count_rastula <- counts
rad_rast  <- raster::raster(allImages[5])
# determine sequence of filters
count_vals <- raster::values(count_rastula)
vals_noNA <- count_vals[!is.na(count_vals)]
seq1 <-seq(min(vals_noNA), max(vals_noNA), by = 1)
# loop over filter values
for(i in seq_along(seq1)){
# run the area function
df$`percent area`[i] <- getArea(values = vals_noNA, index = seq1[i])
# run the mean median function
meanMedian <- radMeanAndMedian(countRaster = count_rastula,
radianceRaster = rad_rast,
index = seq1[i])
# a vector is returned with mean and median values, index to assign it to the correct positions
df[i,3:4] <- meanMedian
}
df
# install and load package
# install.packages("plotly")
library(plotly)
### Plot a figure
p1 <- plot_ly()
p1
p2 <- p1 %>%
add_trace(x = df$filter, y = df$`percent area`,type = 'scatter')
p2
p3 <- p2%>%
<<<<<<< HEAD
add_trace(x=df$filter, y=df$`percent area`,type = 'scatter', line = list(dash = 'dash', shape= "spline"))
=======
add_trace(x = df$filter, y = df$`percent area`,type = 'scatter', line = list(dash = 'dash', shape= "spline"))
>>>>>>> c570d24 (Rproj organization and relative path changes)
p3
p1 <- plot_ly() %>%
add_trace(x = df$filter, y = df$`percent area`,type = 'scatter', line = list(dash = 'dash', shape= "spline"))%>%
layout(xaxis = list(title = "Filter Level"),
yaxis = list(title = "Percentage of Coverage"))
p1
# mean plot
p2 <- plot_ly(x = df$filter, y = df$mean,type = 'scatter', line = list(dash = 'dash', shape= "spline")) %>%
layout(xaxis = list(title = "Filter Level"),
yaxis = list(title = "Mean"))
# median plot
p3 <- plot_ly() %>%
add_trace(x=df$filter, y=df$median,type = 'scatter', line = list(dash = 'dash', shape= "spline"))%>%
layout(xaxis = list(title = "Filter Level"),
yaxis = list(title = "Median"))
p2
p3
p <- plotly::subplot(p1,p2,p3, nrows = 3, shareX = TRUE, titleY = TRUE)
p
<<<<<<< HEAD
# set some standard parameter for the documents.
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# set some standard parameter for the documents.
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# use pacman to load require packages
if (!require("pacman")) install.packages("pacman") ## important because we will be calling this script mulitple times
pacman::p_load(dplyr,raster,tmap,plotly)
# set number of sigfigs
options(scipen=999)
# set tmap to interactive viewing
tmap::tmap_mode("view")
# input features
baseDir <- "D:/R_SC_Spatial/intermediateGeospatialR/"
county <- "Bexar"
months <- c("april", "may", "june", "july")
filters <- c(2,6,10)
### grab imagery for county
images <- list.files(paste0(baseDir,"/data/nightLights/", county), pattern = ".tif", full.names = TRUE)
counts <- list.files(paste0(baseDir,"/data/nightLights/"), pattern = "_counts.tif", full.names = TRUE)
# create a dataframe to store information
# loop over all filter option
for(i in filter){
# create a mask based on the counts raster and filter
# apply that mask to the radiance raster
# detemine all vals excluding NAs
# calculate mean, median and percent area and store in data frame
}
# loop over months
for(i in seq_along(months)){
# select rasters using character match
m <- months[i]
# grab the raster base on match in the file name
r1 <- raster::raster(images[grepl(pattern = m, x = images)])
# create a mask object of the radience feature
mask <- r1
mask[mask > 0] <- 1
mask[mask != 1] <- NA
# determine the total number of cells of interest by sum all values.
totalCells <- sum(values(mask), na.rm = TRUE)
# pull the correct counts feature base on character match and apply mask
count1 <- raster::raster(counts[grepl(pattern = m, x = counts)])*mask
# create df to store results
df1 <- data.frame(matrix(nrow = length(filters), ncol = 5))
colnames(df1) <- c("month","filter","mean","median", "totalArea")
df1$month <- m
df1$filter <- filters
## loop over all seq
for(j in seq_along(filters)){
# generate a mask with the counts image based on the seq value
c2 <- count1
# replace all values based on filter val
c2[c2 < filters[j]] <- NA
# generate a mask base on new filtered data
c2[!is.na(c2)]<- 1
# apply that mask to radaince value
r2 <- r1 * c2
# calculate Mean, median of masked radiance raster
vals <- raster::values(r2)
# drop all na values
vals <- vals[!is.na(vals)]
# calculate values and assign features to dataframe
df1[j,"mean"] <- mean(vals)
df1[j,"median"] <- median(vals)
# count total obervation in mask.
df1[j,"totalArea"] <- 100*(length(vals)/totalCells)
}
# create a new dataframe object on first pass then add directly to that df on
# subsequent passes
if(i == 1){
df <- df1
}else{
df <- dplyr::bind_rows(df, df1)
}
}
# set some standard parameter for the documents.
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# use pacman to load require packages
if (!require("pacman")) install.packages("pacman") ## important because we will be calling this script mulitple times
pacman::p_load(dplyr,raster,tmap,plotly)
# set number of sigfigs
options(scipen=999)
# set tmap to interactive viewing
tmap::tmap_mode("view")
# input features
baseDir <- "D:/R_SC_Spatial/intermediateGeospatialR/"
county <- "Bexar"
months <- c("april", "may", "june", "july")
filters <- c(2,6,10)
### grab imagery for county
images <- list.files(paste0(baseDir,"/data/nightLights/", county), pattern = ".tif", full.names = TRUE)
counts <- list.files(paste0(baseDir,"/data/nightLights/"), pattern = "_counts.tif", full.names = TRUE)
for(m in months){
# call in radiance and counts imagery base on month
# clip and mask the counts imagery based on radiance feature
# create a dataframe to store information
# loop over all filter option
for(i in filter){
# create a mask based on the counts raster and filter
# apply that mask to the radiance raster
# detemine all vals excluding NAs
# calculate mean, median and percent area and store in data frame
}
# Store information from dataframe in comprehesive dataframe.
}
# loop over months
for(i in seq_along(months)){
# select rasters using character match
m <- months[i]
# grab the raster base on match in the file name
r1 <- raster::raster(images[grepl(pattern = m, x = images)])
# create a mask object of the radience feature
mask <- r1
mask[mask > 0] <- 1
mask[mask != 1] <- NA
# determine the total number of cells of interest by sum all values.
totalCells <- sum(values(mask), na.rm = TRUE)
# pull the correct counts feature base on character match and apply mask
count1 <- raster::raster(counts[grepl(pattern = m, x = counts)])*mask
# create df to store results
df1 <- data.frame(matrix(nrow = length(filters), ncol = 5))
colnames(df1) <- c("month","filter","mean","median", "totalArea")
df1$month <- m
df1$filter <- filters
## loop over all seq
for(j in seq_along(filters)){
# generate a mask with the counts image based on the seq value
c2 <- count1
# replace all values based on filter val
c2[c2 < filters[j]] <- NA
# generate a mask base on new filtered data
c2[!is.na(c2)]<- 1
# apply that mask to radaince value
r2 <- r1 * c2
# calculate Mean, median of masked radiance raster
vals <- raster::values(r2)
# drop all na values
vals <- vals[!is.na(vals)]
# calculate values and assign features to dataframe
df1[j,"mean"] <- mean(vals)
df1[j,"median"] <- median(vals)
# count total obervation in mask.
df1[j,"totalArea"] <- 100*(length(vals)/totalCells)
}
# create a new dataframe object on first pass then add directly to that df on
# subsequent passes
if(i == 1){
df <- df1
}else{
df <- dplyr::bind_rows(df, df1)
}
}
i <- i
i <- 1
# select rasters using character match
m <- months[i]
m
# grab the raster base on match in the file name
r1 <- raster::raster(images[grepl(pattern = m, x = images)])
images
### grab imagery for county
images <- list.files(paste0(baseDir,"/data/nightLights/", county), pattern = ".tif", full.names = TRUE)
counts <- list.files(paste0(baseDir,"/data/nightLights/"), pattern = "_counts.tif", full.names = TRUE)
images
images
baseDir
# input features
baseDir <- "F:/R_SC_Spatial/intermediateGeospatialR/"
county <- "Bexar"
months <- c("april", "may", "june", "july")
filters <- c(2,6,10)
### grab imagery for county
images <- list.files(paste0(baseDir,"/data/nightLights/", county), pattern = ".tif", full.names = TRUE)
counts <- list.files(paste0(baseDir,"/data/nightLights/"), pattern = "_counts.tif", full.names = TRUE)
# loop over months
for(i in seq_along(months)){
# select rasters using character match
m <- months[i]
# grab the raster base on match in the file name
r1 <- raster::raster(images[grepl(pattern = m, x = images)])
# create a mask object of the radience feature
mask <- r1
mask[mask > 0] <- 1
mask[mask != 1] <- NA
# determine the total number of cells of interest by sum all values.
totalCells <- sum(values(mask), na.rm = TRUE)
# pull the correct counts feature base on character match and apply mask
count1 <- raster::raster(counts[grepl(pattern = m, x = counts)])*mask
# create df to store results
df1 <- data.frame(matrix(nrow = length(filters), ncol = 5))
colnames(df1) <- c("month","filter","mean","median", "totalArea")
df1$month <- m
df1$filter <- filters
## loop over all seq
for(j in seq_along(filters)){
# generate a mask with the counts image based on the seq value
c2 <- count1
# replace all values based on filter val
c2[c2 < filters[j]] <- NA
# generate a mask base on new filtered data
c2[!is.na(c2)]<- 1
# apply that mask to radaince value
r2 <- r1 * c2
# calculate Mean, median of masked radiance raster
vals <- raster::values(r2)
# drop all na values
vals <- vals[!is.na(vals)]
# calculate values and assign features to dataframe
df1[j,"mean"] <- mean(vals)
df1[j,"median"] <- median(vals)
# count total obervation in mask.
df1[j,"totalArea"] <- 100*(length(vals)/totalCells)
}
# create a new dataframe object on first pass then add directly to that df on
# subsequent passes
if(i == 1){
df <- df1
}else{
df <- dplyr::bind_rows(df, df1)
}
}
df
p1 <- plot_ly() %>%
add_trace(x=df$filter, y=df$mean,type = 'scatter',  line = list(dash = 'dash', shape= "spline"))%>%
layout(xaxis = list(title = "Filter Level "),
yaxis = list(title = "Mean"))
p1
p1 <- plot_ly()%>%
add_trace(x=df$filter, y=df$mean,type = 'scatter', color = df$month, line = list(dash = 'dash', shape= "spline"))%>%
layout(xaxis = list(title = "Filter Level "),
yaxis = list(title = "Mean"))
p1
### generate the three specific plots
# mean
p1 <- plot_ly() %>%
add_trace(x=df$filter, y=df$mean,type = 'scatter', color = df$month, line = list(dash = 'dash', shape= "spline"))%>%
layout(xaxis = list(title = "Filter Level"),
yaxis = list(title = "Mean"))
# median
p2 <- plot_ly() %>%
add_trace(x=df$filter, y=df$median,type = 'scatter', color = df$month, line = list(dash = 'dash', shape= "spline"),     showlegend = FALSE)%>%
layout(xaxis = list(title = "Filter Level"),
yaxis = list(title = "Median"))
# percent area
p3 <- plot_ly() %>%
add_trace(x=df$filter, y=df$totalArea,type = 'scatter', color = df$month, line = list(dash = 'dashdot', shape= "spline"),  showlegend = FALSE) %>%
layout(xaxis = list(title = "Filter Level"),
yaxis = list(title = "Percent Area"))
### create the subplot
p<- plotly::subplot(p1,p2,p3, nrows = 3, shareX = TRUE, titleY = TRUE)
p
=======
>>>>>>> c570d24 (Rproj organization and relative path changes)
