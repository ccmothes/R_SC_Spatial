---
title: "Rasters: Projections and Analysis"
output: rmdcss::html_modest
---

```{r}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning = FALSE)
```

# outline 
- what was cover in last lesson 
  - background to spatial data in R
  - read in raster 
  - csv to spatial data 
  - comparing extent, crs, and cropping data
  - extracting values to points 
  
- what should be covered in this lesson 
  - reading in shape files 
  - reprojecting rasters 
  - reclassiflying rasters 
  - raster stacks 
  - operations over raster stacks 
  
theme : Evaluate the potential of using Night Lights data from VIIRS in a Land Cover classification
basically the code from a night lights project 
- provide NLCD for larger area 
- provide night lights data for two texas counties - one challenge will be looping over the processing  
- provide the counties shapefile 


# Background 
Remote sensing land cover classifications are essential for evaluating landscape scale changes in the human and ecological environmental. These categorical classification are typically generated utilizing multispectral imagery from MODIS, Landsat, or other such sensor. Within the lesson we will be exploring the relationship between the National Land Cover Database 2016 land cover dataset and imagery from the VIIRS Day/Night bands which captures daily night lights imagery across the globe. The belief is that the VIIRS data may be a benifical predictor to include in land cover classifications associated with urban areas. 

# Objectives 
- read in and filter a shapefile using the sf and dplyr libraries 
- reprojecting data   
- reclassifying rasters 
- performing operations over raster stacks 


```{r set libraries}
# install pacman for effecitently installing and loading packages
install.packages("pacman")
#define the packages that are requires 
packages <- c("raster", "dplyr", "tmap", "sf")
# call p_load to see if the package exists, install if needed, and load 
pacman::p_load(packages)
```

```{r read in basic datasets}
# National Land Cover Database dataset 
nlcd <- raster::raster("D:/generalSpatialData/CONUS/NLCD_2016_Land_Cover_L48_20190424/NLCD_2016_Land_Cover_L48_20190424.img")
```

```{r read in the shape file}
# county shapefile
cnt <- sf::read_sf("F:/nrelD/genericSpatialData/US/counties/tl_2017_us_county.shp")
```

Discuss the components of the SF opbject 


```{r read in the complex raster feature}
# list all files to see what is there  
files <- list.files(path = baseDir, pattern = ".tif", 
                      full.names = TRUE, recursive = TRUE)
print(files)
# filter by county of interest 
f2 <- sort(files[grep(pattern = "avg_rade", x = files)])
print(f2)
# reorder the list so it is temporally consisten with our year 
cOrd <- cont[c(5,4,8,1,9,7,6,2,12,11,10,3)]
# create a raster stack of the features 
# lapply : apply a function over a list and returns a list of the same length 
# becomes the input for the the raster stack function 
s1 <- raster::stack(lapply(cOrd, raster::raster))

# view the elements of the stack 

# review what is required for the stack to work... 
### same resolution, extent, and crs 
### the is pretty much the case for any raster operations 

```


```{r prepping the ncld dataset}
# look at the CRS of the NLCD 
nlcd@crs

### discussion on reprojecting rasters 
# computationally intensive operation
# clip first then reproject 


# reproject copy of county feature 
county2 <- sf::st_transform(x = county, crs = nlcd@crs)
# mask and crop nlcd for county

### explain the logic behind crop then mask 
lc <- nlcd %>%
  raster::crop(county2) %>%
  raster::mask(county2)

# reproject nlcd layer 
### more then just a CRS, we are transforming the cell size. 
lc2 <- raster::projectRaster(from = lc, to = s1, crs = s1@crs, method = "ngb")
# for some reason a 0 value is being picked up... this is not part on the NLCD and I'm reclassifying it. This fixes the misclass of the pallette

# look at what land cover is present 
unique(raster::values(lcs))


## reclassifying raster for simplication, reduced number of classes 
lc2[lc2[] ==0 ]<- NA
m <- c(10,12, 1, 20,24, 2,  30, 31, 3, 40,43,4,  50,52, 5, 70,74, 6, 
       80,82, 7,  89,95,8 )
lc2 <- raster::reclassify(x = lc2, rcl = m )

```

```{r apply functions across raster stack}
# median reducer 
me1 <- raster::calc(x = s1, fun = median) %>%
    raster::crop(county) %>%
    raster::mask(county)
# more coplicated example with custom function 
# write function for range
# range returns two values, a min and max. 
range2 <- function(x){
  val <- max(x) - min(x) 
  return(val)
}

range1 <- raster::calc(x = s1, fun = range2, rm.na = TRUE)

```


```{r summary by a few crop classes}
# empty list for holding rasters 
landCoverRasters <- c()
# for all unique values 
for(i in seq_along(unique(values(nlcd)))){
  # create a new object for resampling
  r1 <- nlcd
  # resampe based on indexing on the raster values 
  ### don't want to use resample here because I'm excluding features, just seems easier 
  r1[r1[] != i, ] <- NA 
  r2 <- r1 * me1
  landCoverRasters[i] <- r2
}

# visualize the results 

# generate a summary statistics of layers 